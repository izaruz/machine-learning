m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
makeVector(5)
5
makeVector()
set(1)
mvec<-makeVector()
x<-1:4
mvec$set(x)
mvec$get()
mvec$getmean()
mvec$setmean(3.4)
mvec$getmean()
makeCacheMatrix <- function(x = matrix()) {
inverseM <- NULL
set <- function(y) {
## The simbol <<- set the value in the enviroment
## Is a superassignment
x <<- y
inverseM <<- NULL
}
get <- function() x
setinverseM <- function(inverse) inverseM <<- inverse
getinverseM <- function() inverseM
list(set = set, get = get,
setinverseM = setinverseM,
getinverseM = getinverseM)
}
my-matix<-makeCacheMatrix()
myMatrix<-makeCacheMatrix()
m<-matrix(1:20,10,2)
m
myMatrix$set(m)
inverseM
myMatrix$get()
myMatrix$getinverseM()
myMatrix$setinverseM(m)
myMatrix$getinverseM()
?inverse
cacheSolve <- function(x, ...) {
inverseM <- x$getinverseM()
if(!is.null(inverseM)) {
message("getting cached data")
return(inverseM)
}
mat.data <- x$get()
inverseM <- solve(mat.data, ...)
x$setinverseM(inverseM)
return(inverseM)
}
cacheSolve(myMatrix)
makeCacheMatrix <- function(x = matrix()) {
## @x: a square invertible matrix
## return: a list containing functions to
##              1. set the matrix
##              2. get the matrix
##              3. set the inverse
##              4. get the inverse
##         this list is used as the input to cacheSolve()
inv = NULL
set = function(y) {
# use `<<-` to assign a value to an object in an environment
# different from the current environment.
x <<- y
inv <<- NULL
}
get = function() x
setinv = function(inverse) inv <<- inverse
getinv = function() inv
list(set=set, get=get, setinv=setinv, getinv=getinv)
}
cacheSolve <- function(x, ...) {
## @x: output of makeCacheMatrix()
## return: inverse of the original matrix input to makeCacheMatrix()
inv = x$getinv()
# if the inverse has already been calculated
if (!is.null(inv)){
# get it from the cache and skips the computation.
message("getting cached data")
return(inv)
}
# otherwise, calculates the inverse
mat.data = x$get()
inv = solve(mat.data, ...)
# sets the value of the inverse in the cache via the setinv function.
x$setinv(inv)
return(inv)
}
cacheM<-makeCacheMatrix()
dato<-matrix(1:20,2,10)
cacheM$set(dato)
cacheM$get()
cacheM$getinv()
install.packages("MASS")
ginv(dato)
library(mass)
library("MASS")
ginv(dato)
z<-ginv(dato)
cacheM$setinv(z)
solve<-cacheSolve()
solve<-cacheSolve(cacheM)
solve
library(swirl)
swirl()
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags,class)
cls_list
class(cls_list)
as.character(cls_list)
cls_vect <- sapply(flags,class)
class(cls_vect)
sum(flags$orange)
flags_colors <- flags[,11:17]
flag_colors <- flags[,11:17]
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[,19:23]
lapply(flag_colors, range)
lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes,range)
shape_mat
class(shape_mat)
unique(c(3,4,5,5,5,6,6))
unique_vals <- lapply(flags,unique)
unique_vals
sapply(unique_vals,length)
sapply(flags, unique)
lapply(unique_vals, function(elem) elem[2])
library(swirl)
swirl()
d1<-Sys.Date()
class(d1)
unclass(d1)
d1
d2<-as.Date("1969-01-01")
unclass(d2)
t1<-Sys.time()
t1
class(t1)
unclass(t1)
t2<-as.POSIXlt(Sys.time())
T2
t2
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
d1<-weekdays()
weekdays(d1)
months(t1)
quarters(q1)
quarters(t2$mon)
quarters(t2)
t3<-"October 17, 1986 08:24"
t4<-strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time() > t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
this_day<-today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment<-now()
this_moment
second(this_moment)
my_date<-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
ymd("March 12, 1975")
mdy("March 12, 1975")
mdy(25081985)
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
update(this_moment, hours = 8, minutes = 50, seconds = 30)
update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment<-update(this_moment, hours = 10, minutes = 16, seconds = 0)
this_moment
now()
now("America/New_York")
nyc<-now("America/New_York")
nyc
depart<-nyc+days(2)
depart
depart<-update(this_moment, hours = 17, minutes = 34, seconds = 0)
depart<-update(this_moment, hours = 17, minutes = 34)
depart<-update(depart, hours = 17, minutes = 34)
depart
arrive<-nyc+days(2)
arrive <- depart + hours(15) + minutes(50)
?with_tz
with_tz("Asia/Hong_Kong")
with_tz(Asia/Hong_Kong)
with_tz(tzone="Asia/Hong_Kong")
with_tz(nyx,tzone="Asia/Hong_Kong")
with_tz(nyc,tzone="Asia/Hong_Kong")
with_tz(arrive,tzone="Asia/Hong_Kong")
with_tz(arrive, "Asia/Hong_Kong")
arrive<-with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time<-mdy("June 17, 2008",tz = "Singapore")
last_time
interval(arrive, last_time)
?interval
how_long<-interval(last_time, arrive)
as.period(how_long)
stopwatch()
library(swirl)
install_from_swirl("Exploratory Data Analysis")
swirl()
xyplot(y ~ x | f * g, data)
data
head(airquality)
xyplot(Ozone~Wind, airquality)
xyplot(Ozone~Wind, airquality, col = red, pch = 8, main = "Big Apple Data")
xyplot(Ozone~Wind, airquality, col = "red", pch = 8, main = "Big Apple Data")
xyplot(Ozone ~ Wind, data = airquality, pch=8, col="red", main="Big Apple Data")
xyplot(Ozone ~ Wind, data = airquality, pch=8, col="red", main="Big Apple Data")
xyplot(Ozone ~ Wind | as.factor(Month), data = airquality, layout=c(5,1))
xyplot(Ozone ~ Wind | as.factor(Month), data = airquality, layout=c(5,1))
xyplot(Ozone ~ Wind | Month, data = airquality, layout=c(5,1))
p<-xyplot(Ozone~Wind,data=airquality)
p
p
names(p)
xyplot(Ozone~Wind,data=airquality)
mynames[myfull]
p[["formula"]]
p[["formula"]]
p[["x.limits"]]
p[["x.limits"]]
table(f)
table(f)
xyplot(y ~ x | f, layout = c(2, 1))
v1
v1
v2
myedit("plot1.R")
myedit("plot1.R")
source(pathtofile("plot1.R"),local=TRUE)
myedit("plot2.R")
pathtofile("plot2.R")
source(pathtofile("plot2.R"),local=TRUE)
2
str(diamonds)
str(diamonds)
table(diamonds$color)
table(diamonds$color)
table(diamonds$color,diamonds$cut)
1
myedit("myLabels.R")
pathtofile("myLabels.R")
source(pathtofile("myLabels.R"),local=TRUE)
source(pathtofile("myLabels.R"),local=TRUE)
xyplot(price~carat|color*cut,data=diamonds,strip=FALSE,pch=20,xlab=myxlab,ylab=myylab,main=mymain)
1
xyplot(price~carat|color*cut,data=diamonds,pch=20,xlab=myxlab,ylab=myylab,main=mymain)
?knit2html
knit2html()
library(ggplot2)
library(gridExtra)
install.packages("gridExtra")
qunif(p=0.75, min=0, max=1)
sqrt(0.75)
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
mean(temp)
library(swirl)
install_from_swirl("Statistical Inference")
swirl()
0.08
0.92
2/36
1-((2-1)/36)
0.97
98%
11/12
deck
1/(12*4)
12*4
13*4
4/52
(1/5)+(1/5)+(1/5)+(1+5)/(1+5)
(1/5)+(1/5)+(1/5)+(1+5)
(1/5)*(1/5)*(1/5)*(1+5)
0
12/52
11/51
2/51
(1.6*0.8)/2
1-0.64
0.64/1
mypdf
mypdf(1.6)
integrate(mypdf,0,1.6)
(50*50)/4
2
1
equiv_val(sqrt(2))
1.414214
.997*.001
(1-.985)*(1-.001)
.000997/(.000997+.014985)
0.5
1/6
(1/6)/6
1
3.5
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
3.5
integrate(myfunc,0,2)
spop
mean(spop)
allsam
apply(allsam,1,mean)
mean(smeans)
dice_sqr
ex2_fair<-dice_sqr*dice_fair
ex2_fair <- sum(dice_fair * dice_sqr)
sqrt(ex2_fair)
ex2_fair-3.5^2
sum(dice_high)
sum(dice_high * dice_sqr)-edh^2
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
1/sqrt(120)
sd(apply(matrix(runif(10000),1000),1,mean))
2/sqrt(n)
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
newWeight<-2000/1000
predMpg<-predict(object = fit, newdata = data.frame(wt = newWeight), interval = "predict"); predMpg
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
data<-data.frame(cbind(x, y))
regr<-lm(formula = y~x, data)
coef(summary(regr))
summary(regr)
summary(regr)$sigma
fit<-lm(formula = mpg~wt, data = mtcars)
averageWeight<-mean(mtcars$wt)
b0<-fit$coef[1]; b0
b1<-fit$coef[2]; b1
point<-b0+b1*averageWeight; point
point+c(1,-1)*qt(p = 0.975, df = fit$df)*0.5591
predMpg<-predict(object = fit, newdata = data.frame(wt = newWeight), interval = "predict"); predMpg
newWeight<-3000/1000
predMpg<-predict(object = fit, newdata = data.frame(wt = newWeight), interval = "predict"); predMpg
install.packages(caret)
install.packages("caret")
install.packages("randomForest")
install.packages("e1071")
install.packages("gbm")
install.packages("doParallel")
install.packages("survival")
install.packages("splines")
install.packages("plyr")
install.packages("rpart")
install.packages("rpart.plot")
install.packages("corrplot")
pmlTraining <- read.csv("pmlTraining.csv", header = TRUE, na.strings = c("NA",""))
pmlTesting <- read.csv("pmlTesting.csv", header = TRUE, na.strings = c("NA",""))
getwd()
setwd(../..)
setwd("../..")
getwd()
setwd("C:\Users\izaru\Desktop\DataScience\machine-learning")
setwd("C:/Users/izaru/Desktop/DataScience/machine-learning")
getwd()
pmlTraining <- read.csv("pmlTraining.csv", header = TRUE, na.strings = c("NA",""))
pmlTesting <- read.csv("pmlTesting.csv", header = TRUE, na.strings = c("NA",""))
dim(pmlTraining)
pmlTraining_filter_col <- pmlTraining[,(colSums(is.na(pmlTraining)) == 0)]
pmlTesting_filter_col <- pmlTesting[,(colSums(is.na(pmlTesting)) == 0)]
removeCol <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window")
pmlTrainig_filter_col <- pmlTraining_filter_col[,!(names(pmlTraining_filter_col) %in% removeCol)]
pmlTesting_filter_col <- pmlTesting_filter_col[,!(names(pmlTesting_filter_col) %in% removeCol)]
inTrain = createDataPartition(y = pmlTrainig_filter_col$classe, p = 0.7, list = FALSE)
pmlTraining_sub_data <- pmlTrainig_filter_col[inTrain,]
pmlValid_sub_data <- pmlTrainig_filter_col[-inTrain,]
inTrain = createDataPartition(y = pmlTrainig_filter_col$classe, p = 0.7, list = FALSE)
library(corrplot)
library(caret)
inTrain = createDataPartition(y = pmlTrainig_filter_col$classe, p = 0.7, list = FALSE)
pmlTraining_sub_data <- pmlTrainig_filter_col[inTrain,]
pmlValid_sub_data <- pmlTrainig_filter_col[-inTrain,]
corMatrix<- cor(pmlTraining_sub_data[, -54])
corrplot(corMatrix, order = "FPC", method = "color", type = "lower", tl.cex = 0.8, tl.col = rgb(0, 0, 0))
preProc <- preProcess(pmlTraining_sub_data[, -54], method = "pca", thresh = 0.99)
trainPC <- predict(preProc, pmlTraining_sub_data[, -54])
valid_testPC <- predict(preProc, pmlValid_sub_data[, -54])
modFit <- train(pmlTraining_sub_data$classe ~ ., method = "rf", data = trainPC, trControl = trainControl(method = "cv", number = 4), importance = TRUE)
modFit <- train(pmlTraining_sub_data$classe ~ ., method = "rf", data = trainPC, trControl = trainControl(method = "cv", number = 4), importance = TRUE)
preProc <- preProcess(pmlTraining_sub_data[, -54], method = "pca", thresh = 0.99)
trainPC <- predict(preProc, pmlTraining_sub_data[, -54])
valid_testPC <- predict(preProc, pmlValid_sub_data[, -54])
modFit <- train(pmlTraining_sub_data$classe ~ ., method = "rf", data = trainPC, trControl = trainControl(method = "cv", number = 4), importance = TRUE)
?train
View(pmlTraining_sub_data)
train
modFit <- train(pmlTraining_sub_data$classe, method = "rf", data = trainPC, trControl = trainControl(method = "cv", number = 4))
data(iris)
caretex <- data("iris")
View(data.June)
View(data.June)
pmlTraining <- read.csv("pmlTraining.csv", header = TRUE, na.strings = c("NA",""))
pmlTesting <- read.csv("pmlTesting.csv", header = TRUE, na.strings = c("NA",""))
dim(pmlTraining)
pmlTraining_filter_col <- pmlTraining[,(colSums(is.na(pmlTraining)) == 0)]
pmlTesting_filter_col <- pmlTesting[,(colSums(is.na(pmlTesting)) == 0)]
removeCol <- c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window")
pmlTrainig_filter_col <- pmlTraining_filter_col[,!(names(pmlTraining_filter_col) %in% removeCol)]
pmlTesting_filter_col <- pmlTesting_filter_col[,!(names(pmlTesting_filter_col) %in% removeCol)]
inTrain = createDataPartition(y = pmlTrainig_filter_col$classe, p = 0.7, list = FALSE)
pmlTraining_sub_data <- pmlTrainig_filter_col[inTrain,]
pmlValid_sub_data <- pmlTrainig_filter_col[-inTrain,]
corMatrix<- cor(pmlTraining_sub_data[, -54])
corrplot(corMatrix, order = "FPC", method = "color", type = "lower", tl.cex = 0.8, tl.col = rgb(0, 0, 0))
preProc <- preProcess(pmlTraining_sub_data[, -54], method = "pca", thresh = 0.99)
trainPC <- predict(preProc, pmlTraining_sub_data[, -54])
valid_testPC <- predict(preProc, pmlValid_sub_data[, -54])
modFit <- train(pmlTraining_sub_data$classe ~ ., method = "rf", data = trainPC, trControl = trainControl(method = "cv", number = 4), importance = TRUE)
modFit <- train(pmlTraining_sub_data$classe ~ ., method = "rf", data = trainPC, trControl = trainControl(method = "cv", number = 4))
modFit <- train(pmlTraining_sub_data$classe ~ ., data = trainPC, method = "rf", trControl = trainControl(method = "cv", number = 4))
trainControl(method = "cv", number = 4)
train(pmlTraining_sub_data$classe ~ ., data = trainPC, method = "rf")
data(iris)
TrainData <- iris[,1:4]
TrainClasses <- iris[,5]
knnFit1 <- train(TrainData, TrainClasses,
method = "knn",
preProcess = c("center", "scale"),
tuneLength = 10,
trControl = trainControl(method = "cv"))
knnFit2 <- train(TrainData, TrainClasses,
method = "knn",
preProcess = c("center", "scale"),
tuneLength = 10,
trControl = trainControl(method = "boot"))
modFit <- train(pmlTraining_sub_data$classe ~ ., method = "rf", data = trainPC, trControl = control, importance = TRUE)
control <- trainControl(method = "cv", number = 4)
control <- trainControl(method = "cv", number = 4)
modFit <- train(pmlTraining_sub_data$classe~., data=trainPC, method="rf", trControl=control)
View(trainPC)
control <- trainControl(method = "cv", number = 4)
modFit <- train(pmlTraining_sub_data$classe~., data=trainPC, method="rf", trControl=control)
control <- trainControl(method = "cv", number = 4)
modFit <- train(pmlTraining_sub_data$classe~., data=trainPC, method="rf", trControl=control,prox=TRUE,allowParallel=TRUE)
clear
clean
require(caret)
require(ggplot2)
require(randomForest)
training_URL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_URL<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training<-read.csv(training_URL,na.strings=c("NA",""))
test<-read.csv(test_URL,na.strings=c("NA",""))
training<-training[,7:160]
test<-test[,7:160]
mostly_data<-apply(!is.na(training),2,sum)>19621
training<-training[,mostly_data]
test<-test[,mostly_data]
dim(training)
InTrain<-createDataPartition(y=training$classe,p=0.3,list=FALSE)
training1<-training[InTrain,]
rf_model<-train(classe~.,data=training1,method="rf",
trControl=trainControl(method="cv",number=5),
prox=TRUE,allowParallel=TRUE)
View(training1)
print(rf_model)
print(rf_model$finalModel)
